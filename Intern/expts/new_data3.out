ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Sequential(
    (0): Linear(in_features=512, out_features=2, bias=True)
  )
)
Epoch 0/29
----------
train 0
train Loss: 0.2652 Acc: 0.8839
0.0 tensor(0.8839, dtype=torch.float64)
val 0
/opt/conda/conda-bld/pytorch_1591914855613/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
val Loss: 1.1235 Acc: 0.5302
[0.00000000e+00 5.99880024e-04 2.39952010e-03 ... 9.99400120e-01
 9.99400120e-01 1.00000000e+00] [0.         0.         0.         ... 0.99934641 1.         1.        ] [15.18064976 14.18064976 10.46996593 ...  0.01874305  0.01785509
  0.01659419] 0.5496073334352737
              precision    recall  f1-score   support

           0       0.53      0.82      0.64      1667
           1       0.52      0.22      0.31      1530

    accuracy                           0.53      3197
   macro avg       0.53      0.52      0.48      3197
weighted avg       0.53      0.53      0.48      3197


Epoch 1/29
----------
train 1
train Loss: 0.1263 Acc: 0.9522
tensor(0.8839, dtype=torch.float64) tensor(0.9522, dtype=torch.float64)
val 1
val Loss: 1.7301 Acc: 0.5224
[0.00000000e+00 2.99940012e-04 1.49970006e-03 ... 9.99700060e-01
 9.99700060e-01 1.00000000e+00] [0.        0.        0.        ... 0.9996732 1.        1.       ] [1.51806498e+01 1.41806498e+01 1.04699659e+01 ... 3.92604759e-03
 3.55685758e-03 2.75598071e-03] 0.5415072867779385
              precision    recall  f1-score   support

           0       0.53      0.87      0.66      3334
           1       0.52      0.15      0.23      3060

    accuracy                           0.53      6394
   macro avg       0.52      0.51      0.44      6394
weighted avg       0.52      0.53      0.45      6394


Epoch 2/29
----------
train 2
train Loss: 0.1198 Acc: 0.9527
tensor(0.9522, dtype=torch.float64) tensor(0.9527, dtype=torch.float64)
val 2
val Loss: 1.5273 Acc: 0.5314
[0.00000000e+00 1.99960008e-04 7.99840032e-04 ... 9.99800040e-01
 9.99800040e-01 1.00000000e+00] [0.         0.         0.         ... 0.99956427 1.         1.        ] [2.20643272e+01 2.10643272e+01 1.41806498e+01 ... 3.92604759e-03
 3.33982427e-03 2.75598071e-03] 0.5430259917515408
              precision    recall  f1-score   support

           0       0.53      0.87      0.66      5001
           1       0.52      0.15      0.23      4590

    accuracy                           0.53      9591
   macro avg       0.53      0.51      0.45      9591
weighted avg       0.53      0.53      0.46      9591


Epoch 3/29
----------
train 3
train Loss: 0.1060 Acc: 0.9550
tensor(0.9527, dtype=torch.float64) tensor(0.9550, dtype=torch.float64)
val 3
val Loss: 1.6306 Acc: 0.5286
[0.00000000e+00 1.49970006e-04 1.04979004e-03 ... 9.99550090e-01
 9.99550090e-01 1.00000000e+00] [0.        0.        0.        ... 0.9996732 1.        1.       ] [2.64800186e+01 2.54800186e+01 1.57733002e+01 ... 3.52602731e-03
 2.94723688e-03 2.31527165e-03] 0.5439423879929897
              precision    recall  f1-score   support

           0       0.53      0.88      0.66      6668
           1       0.52      0.15      0.23      6120

    accuracy                           0.53     12788
   macro avg       0.53      0.51      0.45     12788
weighted avg       0.53      0.53      0.46     12788


Epoch 4/29
----------
train 4
train Loss: 0.1018 Acc: 0.9620
tensor(0.9550, dtype=torch.float64) tensor(0.9620, dtype=torch.float64)
val 4
val Loss: 1.9578 Acc: 0.5267
[0.00000000e+00 1.19976005e-04 9.59808038e-04 ... 9.99880024e-01
 9.99880024e-01 1.00000000e+00] [0.         0.         0.         ... 0.99986928 1.         1.        ] [2.64800186e+01 2.54800186e+01 1.57733002e+01 ... 1.80683366e-03
 1.50178198e-03 9.39810358e-04] 0.5424262363213632
              precision    recall  f1-score   support

           0       0.53      0.89      0.66      8335
           1       0.53      0.13      0.21      7650

    accuracy                           0.53     15985
   macro avg       0.53      0.51      0.44     15985
weighted avg       0.53      0.53      0.45     15985


Epoch 5/29
----------
train 5
train Loss: 0.1001 Acc: 0.9595
val 5
val Loss: 1.8892 Acc: 0.5267
[0.00000000e+00 9.99800040e-05 1.09978004e-03 ... 9.99700060e-01
 9.99700060e-01 1.00000000e+00] [0.         0.         0.         ... 0.99978214 1.         1.        ] [2.64800186e+01 2.54800186e+01 1.57733002e+01 ... 1.80683366e-03
 1.50178198e-03 9.39810358e-04] 0.5421406023806132
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     10002
           1       0.53      0.13      0.21      9180

    accuracy                           0.53     19182
   macro avg       0.53      0.51      0.44     19182
weighted avg       0.53      0.53      0.45     19182


Epoch 6/29
----------
train 6
train Loss: 0.0907 Acc: 0.9653
tensor(0.9620, dtype=torch.float64) tensor(0.9653, dtype=torch.float64)
val 6
val Loss: 1.7733 Acc: 0.5289
[0.00000000e+00 8.56971463e-05 1.11406290e-03 ... 9.99657211e-01
 9.99657211e-01 1.00000000e+00] [0.         0.         0.         ... 0.99981326 1.         1.        ] [2.64800186e+01 2.54800186e+01 1.57733002e+01 ... 1.80683366e-03
 1.50178198e-03 9.39810358e-04] 0.5422254404661284
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     11669
           1       0.53      0.13      0.21     10710

    accuracy                           0.53     22379
   macro avg       0.53      0.51      0.44     22379
weighted avg       0.53      0.53      0.44     22379


Epoch 7/29
----------
train 7
train Loss: 0.0955 Acc: 0.9623
val 7
val Loss: 1.8369 Acc: 0.5271
[0.00000000e+00 7.49850030e-05 1.19976005e-03 ... 9.99625075e-01
 9.99625075e-01 1.00000000e+00] [0.        0.        0.        ... 0.9998366 1.        1.       ] [2.64800186e+01 2.54800186e+01 1.53425055e+01 ... 1.80683366e-03
 1.50178198e-03 9.39810358e-04] 0.5420960967120301
              precision    recall  f1-score   support

           0       0.53      0.90      0.66     13336
           1       0.53      0.13      0.20     12240

    accuracy                           0.53     25576
   macro avg       0.53      0.51      0.43     25576
weighted avg       0.53      0.53      0.44     25576


Epoch 8/29
----------
train 8
train Loss: 0.0838 Acc: 0.9669
tensor(0.9653, dtype=torch.float64) tensor(0.9669, dtype=torch.float64)
val 8
val Loss: 1.6432 Acc: 0.5292
[0.00000000e+00 6.66533360e-05 1.26641338e-03 ... 9.99666733e-01
 9.99666733e-01 1.00000000e+00] [0.         0.         0.         ... 0.99985476 1.         1.        ] [2.71659546e+01 2.61659546e+01 1.53425055e+01 ... 1.66145479e-03
 1.50178198e-03 9.39810358e-04] 0.5421358841279432
              precision    recall  f1-score   support

           0       0.53      0.90      0.66     15003
           1       0.53      0.13      0.21     13770

    accuracy                           0.53     28773
   macro avg       0.53      0.51      0.43     28773
weighted avg       0.53      0.53      0.44     28773


Epoch 9/29
----------
train 9
train Loss: 0.0909 Acc: 0.9637
val 9
val Loss: 1.7204 Acc: 0.5286
[0.00000000e+00 5.99880024e-05 1.31973605e-03 ... 9.99700060e-01
 9.99700060e-01 1.00000000e+00] [0.         0.         0.         ... 0.99993464 1.         1.        ] [2.71659546e+01 2.61659546e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5419978710140325
              precision    recall  f1-score   support

           0       0.53      0.90      0.66     16670
           1       0.53      0.13      0.21     15300

    accuracy                           0.53     31970
   macro avg       0.53      0.51      0.44     31970
weighted avg       0.53      0.53      0.44     31970


Epoch 10/29
----------
train 10
train Loss: 0.0928 Acc: 0.9650
val 10
val Loss: 1.8210 Acc: 0.5274
[0.00000000e+00 5.45345476e-05 1.36336369e-03 ... 9.99672793e-01
 9.99672793e-01 1.00000000e+00] [0.         0.         0.         ... 0.99994058 1.         1.        ] [2.71659546e+01 2.61659546e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5418421890083173
              precision    recall  f1-score   support

           0       0.53      0.90      0.66     18337
           1       0.53      0.13      0.20     16830

    accuracy                           0.53     35167
   macro avg       0.53      0.51      0.43     35167
weighted avg       0.53      0.53      0.44     35167


Epoch 11/29
----------
train 11
train Loss: 0.0939 Acc: 0.9652
val 11
val Loss: 1.7454 Acc: 0.5261
[0.00000000e+00 4.99900020e-05 1.39972006e-03 ... 9.99650070e-01
 9.99650070e-01 1.00000000e+00] [0.         0.         0.         ... 0.99994553 1.         1.        ] [2.71659546e+01 2.61659546e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5416968430932549
              precision    recall  f1-score   support

           0       0.53      0.90      0.66     20004
           1       0.53      0.13      0.20     18360

    accuracy                           0.53     38364
   macro avg       0.53      0.51      0.43     38364
weighted avg       0.53      0.53      0.44     38364


Epoch 12/29
----------
train 12
train Loss: 0.0837 Acc: 0.9684
tensor(0.9669, dtype=torch.float64) tensor(0.9684, dtype=torch.float64)
val 12
val Loss: 1.6555 Acc: 0.5286
[0.00000000e+00 4.61446172e-05 1.43048313e-03 ... 9.99676988e-01
 9.99676988e-01 1.00000000e+00] [0.         0.         0.         ... 0.99994972 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5416514283870224
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     21671
           1       0.53      0.13      0.21     19890

    accuracy                           0.53     41561
   macro avg       0.53      0.51      0.44     41561
weighted avg       0.53      0.53      0.44     41561


Epoch 13/29
----------
train 13
train Loss: 0.0939 Acc: 0.9637
val 13
val Loss: 1.6845 Acc: 0.5296
[0.00000000e+00 4.28485731e-05 1.45685149e-03 ... 9.99657211e-01
 9.99657211e-01 1.00000000e+00] [0.         0.         0.         ... 0.99995331 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5417692171849744
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     23338
           1       0.53      0.13      0.21     21420

    accuracy                           0.53     44758
   macro avg       0.53      0.51      0.44     44758
weighted avg       0.53      0.53      0.45     44758


Epoch 14/29
----------
train 14
train Loss: 0.0972 Acc: 0.9634
val 14
val Loss: 1.8410 Acc: 0.5267
[0.00000000e+00 3.99920016e-05 1.47970406e-03 ... 9.99640072e-01
 9.99640072e-01 1.00000000e+00] [0.         0.         0.         ... 0.99995643 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5417528842815315
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     25005
           1       0.53      0.13      0.21     22950

    accuracy                           0.53     47955
   macro avg       0.53      0.51      0.44     47955
weighted avg       0.53      0.53      0.44     47955


Epoch 15/29
----------
train 15
train Loss: 0.0953 Acc: 0.9606
val 15
val Loss: 1.7877 Acc: 0.5271
[0.00000000e+00 3.74925015e-05 1.49970006e-03 ... 9.99625075e-01
 9.99625075e-01 1.00000000e+00] [0.         0.         0.         ... 0.99995915 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5416049717446216
              precision    recall  f1-score   support

           0       0.53      0.90      0.66     26672
           1       0.53      0.13      0.20     24480

    accuracy                           0.53     51152
   macro avg       0.53      0.51      0.43     51152
weighted avg       0.53      0.53      0.44     51152


Epoch 16/29
----------
train 16
train Loss: 0.0898 Acc: 0.9667
val 16
val Loss: 1.6759 Acc: 0.5261
[0.00000000e+00 3.52870602e-05 1.51734359e-03 ... 9.99647129e-01
 9.99647129e-01 1.00000000e+00] [0.         0.         0.         ... 0.99996155 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5415226019183164
              precision    recall  f1-score   support

           0       0.53      0.90      0.66     28339
           1       0.53      0.13      0.21     26010

    accuracy                           0.53     54349
   macro avg       0.53      0.51      0.43     54349
weighted avg       0.53      0.53      0.44     54349


Epoch 17/29
----------
train 17
train Loss: 0.0858 Acc: 0.9669
val 17
val Loss: 1.7608 Acc: 0.5305
[0.00000000e+00 3.33266680e-05 1.53302673e-03 ... 9.99633407e-01
 9.99633407e-01 1.00000000e+00] [0.         0.         0.         ... 0.99996369 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5415875545539646
              precision    recall  f1-score   support

           0       0.53      0.90      0.66     30006
           1       0.53      0.13      0.21     27540

    accuracy                           0.53     57546
   macro avg       0.53      0.51      0.43     57546
weighted avg       0.53      0.53      0.44     57546


Epoch 18/29
----------
train 18
train Loss: 0.0939 Acc: 0.9637
val 18
val Loss: 1.6994 Acc: 0.5280
[0.00000000e+00 3.15726328e-05 1.54705901e-03 ... 9.99652701e-01
 9.99652701e-01 1.00000000e+00] [0.        0.        0.        ... 0.9999656 1.        1.       ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5415250918639258
              precision    recall  f1-score   support

           0       0.53      0.90      0.66     31673
           1       0.53      0.13      0.21     29070

    accuracy                           0.53     60743
   macro avg       0.53      0.51      0.44     60743
weighted avg       0.53      0.53      0.44     60743


Epoch 19/29
----------
train 19
train Loss: 0.0928 Acc: 0.9616
val 19
val Loss: 1.6856 Acc: 0.5283
[0.00000000e+00 2.99940012e-05 1.55968806e-03 ... 9.99640072e-01
 9.99640072e-01 1.00000000e+00] [0.         0.         0.         ... 0.99996732 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.541487443687733
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     33340
           1       0.53      0.13      0.21     30600

    accuracy                           0.53     63940
   macro avg       0.53      0.51      0.44     63940
weighted avg       0.53      0.53      0.45     63940


Epoch 20/29
----------
train 20
train Loss: 0.0881 Acc: 0.9655
val 20
val Loss: 1.6698 Acc: 0.5286
[0.00000000e+00 2.85657154e-05 1.57111435e-03 ... 9.99657211e-01
 9.99657211e-01 1.00000000e+00] [0.         0.         0.         ... 0.99996888 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5415141723778316
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     35007
           1       0.53      0.13      0.21     32130

    accuracy                           0.53     67137
   macro avg       0.53      0.51      0.44     67137
weighted avg       0.53      0.53      0.45     67137


Epoch 21/29
----------
train 21
mura_new_data.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
train Loss: 0.0908 Acc: 0.9637
val 21
val Loss: 1.8422 Acc: 0.5280
[0.00000000e+00 2.72672738e-05 1.58150188e-03 ... 9.99645525e-01
 9.99645525e-01 1.00000000e+00] [0.         0.         0.         ... 0.99997029 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5414357693199653
              precision    recall  f1-score   support

           0       0.53      0.90      0.66     36674
           1       0.53      0.13      0.21     33660

    accuracy                           0.53     70334
   macro avg       0.53      0.51      0.43     70334
weighted avg       0.53      0.53      0.44     70334


Epoch 22/29
----------
train 22
mura_new_data.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
train Loss: 0.0912 Acc: 0.9645
val 22
val Loss: 1.7074 Acc: 0.5261
[0.00000000e+00 2.60817402e-05 1.59098615e-03 ... 9.99660937e-01
 9.99660937e-01 1.00000000e+00] [0.         0.         0.         ... 0.99997158 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.541424927883692
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     38341
           1       0.53      0.13      0.21     35190

    accuracy                           0.53     73531
   macro avg       0.53      0.51      0.44     73531
weighted avg       0.53      0.53      0.44     73531


Epoch 23/29
----------
train 23
mura_new_data.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
train Loss: 0.0973 Acc: 0.9608
val 23
val Loss: 1.7747 Acc: 0.5258
[0.00000000e+00 2.49950010e-05 1.59968006e-03 ... 9.99650070e-01
 9.99650070e-01 1.00000000e+00] [0.         0.         0.         ... 0.99997277 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5413800307748907
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     40008
           1       0.53      0.13      0.21     36720

    accuracy                           0.53     76728
   macro avg       0.53      0.51      0.43     76728
weighted avg       0.53      0.53      0.44     76728


Epoch 24/29
----------
train 24
mura_new_data.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
train Loss: 0.0972 Acc: 0.9623
val 24
val Loss: 1.7389 Acc: 0.5271
[0.00000000e+00 2.39952010e-05 1.60767846e-03 ... 9.99664067e-01
 9.99664067e-01 1.00000000e+00] [0.         0.         0.         ... 0.99997386 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5413366349475203
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     41675
           1       0.53      0.13      0.21     38250

    accuracy                           0.53     79925
   macro avg       0.53      0.51      0.43     79925
weighted avg       0.53      0.53      0.44     79925


Epoch 25/29
----------
train 25
mura_new_data.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
train Loss: 0.1007 Acc: 0.9595
val 25
val Loss: 1.5927 Acc: 0.5277
[0.00000000e+00 2.30723086e-05 1.61506160e-03 ... 9.99676988e-01
 9.99676988e-01 1.00000000e+00] [0.         0.         0.         ... 0.99997486 1.         1.        ] [2.81764431e+01 2.71764431e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5412608573539962
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     43342
           1       0.53      0.13      0.21     39780

    accuracy                           0.53     83122
   macro avg       0.53      0.51      0.44     83122
weighted avg       0.53      0.53      0.44     83122


Epoch 26/29
----------
train 26
mura_new_data.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
train Loss: 0.0898 Acc: 0.9641
val 26
val Loss: 1.5942 Acc: 0.5283
[0.00000000e+00 2.22177787e-05 1.62189784e-03 ... 9.99688951e-01
 9.99688951e-01 1.00000000e+00] [0.         0.         0.         ... 0.99997579 1.         1.        ] [2.88354683e+01 2.78354683e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5412473765501343
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     45009
           1       0.53      0.13      0.21     41310

    accuracy                           0.53     86319
   macro avg       0.53      0.51      0.44     86319
weighted avg       0.53      0.53      0.45     86319


Epoch 27/29
----------
train 27
mura_new_data.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
train Loss: 0.0979 Acc: 0.9613
val 27
val Loss: 1.7760 Acc: 0.5261
[0.00000000e+00 2.14242866e-05 1.62824578e-03 ... 9.99678636e-01
 9.99678636e-01 1.00000000e+00] [0.         0.         0.         ... 0.99997666 1.         1.        ] [2.88354683e+01 2.78354683e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5411976693296795
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     46676
           1       0.53      0.13      0.21     42840

    accuracy                           0.53     89516
   macro avg       0.53      0.51      0.44     89516
weighted avg       0.53      0.53      0.45     89516


Epoch 28/29
----------
train 28
mura_new_data.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
train Loss: 0.0982 Acc: 0.9627
val 28
val Loss: 1.7673 Acc: 0.5283
[0.00000000e+00 2.06855181e-05 1.63415593e-03 ... 9.99689717e-01
 9.99689717e-01 1.00000000e+00] [0.         0.         0.         ... 0.99997746 1.         1.        ] [2.88354683e+01 2.78354683e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5411571983707756
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     48343
           1       0.53      0.13      0.21     44370

    accuracy                           0.53     92713
   macro avg       0.53      0.51      0.44     92713
weighted avg       0.53      0.53      0.45     92713


Epoch 29/29
----------
train 29
mura_new_data.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
train Loss: 0.0954 Acc: 0.9633
val 29
mura_new_data.py:36: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
val Loss: 1.8223 Acc: 0.5258
[0.00000000e+00 1.99960008e-05 1.63967207e-03 ... 9.99680064e-01
 9.99680064e-01 1.00000000e+00] [0.         0.         0.         ... 0.99997821 1.         1.        ] [2.88354683e+01 2.78354683e+01 1.53425055e+01 ... 1.50850182e-03
 1.50178198e-03 9.39810358e-04] 0.5411001851917199
              precision    recall  f1-score   support

           0       0.53      0.89      0.66     50010
           1       0.53      0.13      0.21     45900

    accuracy                           0.53     95910
   macro avg       0.53      0.51      0.44     95910
weighted avg       0.53      0.53      0.44     95910


Training complete in 126m 44s
Best val Acc: 0.531436
